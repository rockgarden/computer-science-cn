# 用WEKA进行数据挖掘

[数据科学](https://www.baeldung.com/cs/category/ai/data-science)

1. 简介

    谁是我们的 "潜在" 客户？我们即将推出的产品应具备哪些功能？这些都是如今每家公司都想知道的问题。

    为了找到这样的答案，公司急于收集和堆积数据。尼尔森的标语也是如此： "人们看什么、听什么、买什么" 的标语收集了各种类型的数据。尽管如此，更多的数据并不意味着更多的知识。

    可以看出，结构化和非结构化两种类型的数据都构成了数字世界。在这种情况下，从大量数据中提取知识对决策起着至关重要的作用。我们可以利用数据挖掘工具来预测趋势，并以此为基础做出知识驱动型决策。

    在本教程中，我们将学习 [WEKA](https://www.cs.waikato.ac.nz/ml/weka/) 数据挖掘工具。

2. 数据挖掘

    简单地说，数据挖掘是在大型数据集中寻找模式和关联以预测结果的过程。这些结果揭示了数据中的趋势、共同主题或模式。

    例如，一家超级市场的老板想知道哪些商品经常一起购买。在分析了顾客几周的交易后，他发现：

    - 当顾客购买牛奶时，面包的销量竟然增加了 75
    - 60%的人喜欢在购买牛奶和面包的同时购买鸡蛋
    综上所述，店主将确保商店在正确的时间和地点提供足够的产品，以增加收入。

    数据挖掘有助于公司发现急需的知识。

    1. 数据挖掘过程

        数据挖掘过程包括几个步骤。首先，进行数据采集、清理和整合。然后，由于不同的数据集来自不同的来源，因此有必要消除不一致之处，并使所有数据集保持一致。

        接着，[选择合适的特征](https://www.baeldung.com/cs/feature-selection-reduction-for-text-classification)。一般来说，数据有很多不相关的属性和维度。因此，选择正确的属性和降低维度对于产生高质量的结果至关重要。

        然后是为下划线问题选择合适的算法。每种类型的问题都有特定的算法。因此，必须准确了解这是[分类问题还是聚类问题](https://www.baeldung.com/cs/ml-classification-vs-clustering)。

        最后，对数据挖掘算法生成的模式和规则进行解释，以获得有用的知识。

3. WEKA

    WEKA 是一个包含用于数据挖掘任务的机器学习算法的工作平台。总体而言，这些任务从数据准备到数据可视化，从分类到聚类，不一而足。尽管 WEKA 的优势在于分类，但它也能高效地执行回归、聚类和关联规则挖掘。

    WEKA 是一个开源工具包，采用 GNU 通用公共许可证（GNU General Public License）。

    1. 要求与安装

        我们可以在 Windows、MAC OS 和 Linux 上安装 WEKA。最低要求是最新稳定版本的 Java 8 或以上。

        如上图所示，应用程序类别中有五个可用选项。资源管理器是执行大多数数据挖掘任务的中心面板。我们将在接下来的章节中进一步探讨该面板。

        除了资源管理器，该工具还提供了一个实验器面板。在这个面板下，我们不仅可以运行实验，还可以设计实验。

        一方面，我们有资源管理器和实验器，另一方面，WEKA 还提供了知识流面板。它提供了一个界面，可以拖放组件，将它们连接起来形成知识流，并分析数据和结果。

        Simple CLI 面板提供了运行 WEKA 的命令行权限。例如，要在 iris.arff 数据上启动 ZeroR 分类器，我们将通过命令行运行：

        `java weka.classifiers.trees.ZeroR -t iris.arff`
    2. 数据集

        数据集是任何数据挖掘任务的基本要素。在本教程中，我们将使用 [Iris 数据集](http://archive.ics.uci.edu/ml/datasets/Iris)来训练和测试几种算法。多元数据集包含三个物种和四个特征。

    3. 数据类型和格式

        数字（整数和实数）、字符串、日期和关系是 WEKA 提供的仅有的四种数据类型。默认情况下，WEKA 支持 ARFF 格式。ARFF 即属性相关文件格式，是一种 ASCII 格式，用于描述共享一组属性的实例列表。

        每个 ARFF 文件都有两个部分：标题和数据。标题部分包含属性类型，数据部分包含以逗号分隔的属性数据列表。需要注意的是，标头（@attribute）和数据（@data）的声明不区分大小写。

        让我们看看天气预报数据集的格式：

        ```arff
        @attribute outlook {sunny,overcast,rainy}
        @attribute tempreture {hot,mild,cool}
        @attribute humidity {high,normal}
        @attribute windy {TRUE,FALSE}
        @attribute play {yes,no}

        @data
        sunny,hot,high,FALSE,no
        sunny,hot,high,TRUE,yes
        overcast,hot,high,TRUE,yes
        overcast,cool,normal,TRUE,yes
        rainy,cool,normal,FALSE,no
        rainy,cool,normal,TRUE,no
        ```

        除 ARFF 外，该工具还支持 [CSV](https://www.baeldung.com/java-csv-file-array)、[JSON](https://www.baeldung.com/java-json) 和 XRFF 等不同文件格式。

    4. 加载数据

        WEKA 允许您从以下四种来源加载数据：

        - 本地文件系统
        - 公共 URL
        - 查询数据库
        - 生成人工数据以运行模型

        从不同来源加载数据后，下一步就是对数据进行预处理。为此，我们可以选择任何合适的过滤技术。所有方法都有默认设置，点击名称即可进行配置。

        如果某个属性（如 sepallength）中存在错误/异常值，我们可以从 "Attributes" 部分删除/更新它。

    5. 机器学习算法类型

        WEKA 为机器学习任务提供了大量算法。由于其核心性质，所有算法都分为几组。这些算法可在 WEKA 的 "Explorer" 选项卡下找到。

        让我们来看看这些组及其核心性质：

        - bayes（贝叶斯）--包括基于贝叶斯定理的算法，如：奈夫贝叶斯
        - functions（函数） - 包含估计函数的算法，包括线性回归
        - lazy - 包括所有使用懒学习的算法，如 KStar、LWL
        - meta - 包括在工作中使用或整合多种算法的算法，如堆叠算法、套袋算法
        - misc - 不符合任何给定类别的杂项算法
        - rules - 结合使用规则的算法，如 OneR、ZeroR
        - trees - 包含使用决策树的算法，如 J48、RandomForest
        每种算法都有配置参数，如 batchSize、debug 等。有些配置参数在所有算法中通用，有些则是特定的。一旦选定要使用的算法，就可以编辑这些配置。

4. WEKA 的功能

    1. 预处理

        数据预处理是数据挖掘中的一项重要任务。因为大多数数据都是原始数据，有可能包含空值或重复值、垃圾值、异常值、额外列或不同的命名规则。所有这些都会降低结果的质量。

        为了使数据更干净、更好和更全面，WEKA 在过滤器类别下提供了一套全面的选项。在这里，该工具提供了监督和非监督类型的操作。

        以下是一些预处理操作的列表：

        - ReplaceMissingWithUserConstant（用用户常数替换缺失值） - 修复空值或空值问题
        - ReservoirSample - 生成样本数据的随机子集
        - NominalToBinary - 将数据从标称值转换为二进制值
        - RemovePercentage - 移除给定百分比的数据
        - RemoveRange - 删除给定范围的数据
    2. 分类

        [分类](https://www.baeldung.com/cs/classification-model-evaluation)是机器学习的基本功能之一，我们通过分类为项目分配类别。分类的经典例子包括：将脑肿瘤宣布为 "恶性" 或 "良性"，或将电子邮件归入 "垃圾邮件" 或 "非垃圾邮件" 类。

        在选择了所需的分类器后，我们还要为训练集选择测试选项。其中包括

        - 使用训练集--分类器将在相同的训练集上进行测试
        - 提供测试集--根据单独的测试集对分类器进行评估
        - 交叉验证折叠数--使用提供的折叠数根据交叉验证对分类器进行评估
        - 百分比分割--根据特定百分比的数据对分类器进行评判
        除此以外，我们还可以使用更多测试选项，如保留百分比拆分顺序、输出源代码等。

        让我们将 ZeroR 分类器应用于数据集。首先，该分类器是 0-R 分类器的实现，允许批量处理。成功执行后，该工具会生成摘要，并根据不同参数展示算法的有效性：

        工具会将结果保存在结果列表(Result list)。
    3. 聚类

        在[聚类](https://www.baeldung.com/java-k-means-clustering-algorithm)中，数据集会根据某些相似性被排列成不同的组/簇。在这种情况下，同一簇内的项目相同，但与其他簇不同。聚类的例子包括但不限于识别具有相似行为的客户、根据同质的土地使用情况组织区域等。

        当我们应用 EM 算法时，工具会显示聚类和属性的平均值和[标准偏差](https://www.baeldung.com/cs/normalize-table-features#3-normalization-by-standard-deviation)。

        Weka 聚类
        让我们看看结果是如何绘制的：

        weka 聚类可视化
        WEKA 提供的最常用聚类算法是 SimpleKMeans、HierarchicalClusterer 和 EM。

    4. 关联

        关联规则强调数据集项之间的所有关联和相关性。简而言之，它是一个 if-then 语句，描述了数据项之间关系的概率。关联的一个典型例子是牛奶和面包销售之间的联系。

        在这一类中，该工具提供 Apriori、FilteredAssociator 和 FPGrowth 算法用于关联规则挖掘。

    5. 选择属性

        每个数据集都包含大量属性，但其中一些属性可能并不重要。因此，去除不必要的属性并保留相关细节对于建立一个好的模型非常重要。

        有许多属性评估器和搜索方法，包括 BestFirst、GreedyStepwise 和 Ranker。

    6. 可视化

        在 "visualize" 选项卡中，可使用不同的绘图矩阵和图表来显示模型确定的趋势和误差。

        虹膜数据集的部分数值如下

        weka 可视化
5. 结论

    从零售市场到医疗保健，从体育运动到监控，数据分析无处不在。毫无疑问，从原始数据中提取知识需要付出大量努力。这些提取出来的知识可以帮助我们制定智能决策、开展准确的营销活动、增加收入、改善客户关系、降低风险和检测在线欺诈。

    在本文中，我们了解了 WEKA，这是一个用于数据挖掘任务的综合工具包。从数据清理到选择特征，以及在每个类别中应用不同的算法，该工具提供了许多选项。归根结底，WEKA 使处理大型数据集和比较各种输出结果变得更加容易。

[Data Mining in WEKA](https://www.baeldung.com/cs/weka-data-mining)
